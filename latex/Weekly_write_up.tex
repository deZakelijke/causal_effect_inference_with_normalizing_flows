\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{tikz}
\usepackage{standalone}
\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage[a4paper, total={7in, 10in}]{geometry}
\usepackage{hyperref}
\usepackage{pbox}

\usepackage{tikz}
\usetikzlibrary{shapes.geometric}
\usepackage{standalone}
\usepackage{graphicx, color}

\newcommand{\bA}{\mathbf{A}}
\newcommand{\bB}{\mathbf{B}}
\newcommand{\bC}{\mathbf{C}}
\newcommand{\bD}{\mathbf{D}}
\newcommand{\E}{\mathbb{E}}
\newcommand{\f}{\mathbf{f}}
\newcommand{\bg}{\mathbf{g}}
\newcommand{\bh}{\mathbf{h}}
\newcommand{\bL}{\mathbf{L}}
\newcommand{\Loss}{\mathcal{L}}
\newcommand{\bM}{\mathbf{M}}
\newcommand{\bN}{\mathbf{N}}
\newcommand{\Norm}{\mathcal{N}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\bt}{\mathbf{t}}
\newcommand{\bU}{\mathbb{U}}
\newcommand{\bu}{\mathbf{u}}
\newcommand{\bw}{\mathbf{w}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\bx}{\mathbf{x}}
\newcommand{\by}{\mathbf{y}}
\newcommand{\bZ}{\mathbf{Z}}
\newcommand{\bz}{\mathbf{z}}

\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\bLam}{\boldsymbol{\Lambda}}

\newcommand{\eq}{=}
\newcommand{\parfrac}[2]{\frac{\partial #1}{\partial#2}}
\newcommand{\inv}{^{-1}}
\newcommand{\twovec}[2]{\begin{pmatrix} #1 \\ #2 \end{pmatrix}}
\newcommand{\threevec}[3]{\begin{pmatrix} #1 \\ #2 \\ #3\end{pmatrix}}

\title{Causal Effect Inference with Normalizing Flows}
\author{Micha de Groot}
\date{August 2019}

\begin{document}


\noindent
% The last idea was as follows:
% \vspace{0.5cm}
% \fbox{\parbox{0.8\textwidth}{
% We have: $\quad f(x, t, y) = z \quad$ and $\quad g(z, t) = y \quad$ with $\quad x \in \mathbb{R}^n \quad t \in \mathbb{R}^m \quad y \in \mathbb{R}^k $


% If $f$ were invertible then $ z \in \mathbb{R}^{n+m+k}$, but if $g$ were invertible then $z \in \mathbb{R}^{k-m}$
% }}

% \noindent
% The dimensionality problem with that idea seems solvable and I have found some possible leads. But before I started working out the details I realised that there are two other, more fundamental problems with this idea. In this idea we assume that $f$ and $g$ exist and can be learned through a normalising flow algorithm. That $f$ exists is plausible, since the combination of all three variables gives enough information to get $z$. But if we wanted to learn $g$ with normalising flows, we would have to do that through its inverse. Otherwise we couldn't optimise the log likelihood. More formally put:
% $$
% \log p(y) = \log p(z,t) - \sum \log \det \left|\parfrac{g}{z,t} \right|
% $$
% Now the problem here is that we would need to define a parameterised distribution over $y$ if we want to optimise $g$ by mapping from $z,t$ to $y$. What is more common, in models such as the RealNVP is to map from the observed variables to the latent variables and then calculate the log likelihood from those samples based on the change of variable equation. But in our case it is not possible to invert this model and get sensible results. We could of course just invert the neural network but it wouldn't make sense. This is because only $y$ doesn't give enough information to distinguish between $z$ and $t$ because of the latent confounding. Imagine a patient from which we only know that it died. Without any additional information we can't know if this was caused by the treatment $t$ or by some prior condition, represented by $z$. 

% I'm not sure about the following statement, but I think that in general it is not possible to invert a collider node in a Bayesian net/Structural causal model when there are no other nodes. That would be similar to Independent Component Analysis where we know that there are more sources than observations.

% \vspace{1cm}
% \noindent
% That is why I thought about dropping that idea and designing some model where we only have one flow that we can just invert. We still have in a sense the problem that if we want to do an intervention to get $y$ we have $t$ on one side of the flow and if we want to do an inference to get $z$ we have $t$ on the other side of the flow. I drew some inspiration from the idea of a context variable, used in Inverse Autoregressive Flow and Sylvester Flow, to make $t$ a part of the context instead of the input of the flow itself. Then we would have one function: $f(x,y;t) = z$ that we can invert: $f(z;t)^{-1} = x,y$. What we lose with this approach is the ability to predict $t$ for a given $x$ or $z$ but that wasn't really a useful feature to have. The 'only' thing that that has to be considered is that if we infer z: $z = f(x,y;t)$, and then want to ask a counterfactual question "What if $t$ had been $\hat{t}$?", then inverting $z$ with a new context should only yield a different value for $y$, not for $x$: $x, \hat{y} = f(z;\hat{t})$. But that seems a solvable problem.

% One way we could do that is start with two separate inputs from $x$ and $y$, and that both first to through several (coupling) layers. Then we concatenate these two intermediate representations and pass them through additional (coupling) layers to get the final log likelihood. So then we would only ever have the log likelihood of a pair $x, y$. 

% Because we are using normalising flows we could, after training, also query interesting things like: What is a more likely outcome for this intervention. The weird thing is that with this model we can make counterfactual queries but not regular intervention questions without first having a observation of the outcome of some random intervention. We do have the possibility to sample from $z$ of course. If we can sample from $z$ in such a way that the corresponding $x$ is close to a sample that we are looking for we can still do regular intervention queries. 




% \noindent
% We are considering two ideas as an improvement upon the causal VAE. I've listed them here with their positive and negative properties.
\section{Models}
Here is a list of the models. The first few are the same as earlier documents I sent and are just here for completeness. The Normalising Causal Flow(NCF) in 1.0.4 is a new-ish model that I haven't discussed with you before, but is based on 1.0.3 and a paper you sent me a while ago.

\subsubsection{CEVAE}
The CEVAE (Causal effect VAE) consist of an encoder and a decoder. The encoder maps from the observed variables to the parameters of the variational latent distribution $q(z|x,t,y)$, which we call $f$. The decoder maps from a sample of the latent variable back to the parameters of the observed variables. Conditioning on $z$ makes certain variables independent so the decoding is split into three separate networks.One network, $g_1$, maps from the latent variable to the parameters of the intervention distribution $p(t|z)$, one function, $g_2$, from the latent variable and the intervention variable to the outcome distribution $p(y|t,z)$. During training the observed value for the intervention variable is inserted her and during testing it is sampled from $p(t,z)$ The third function, $g_3$, maps from the latent variable to the distribution of the proxy variable $p(x|z)$. By setting the input $t$ to a specific value, $g_2$ can be used to do an intervention.

During testing we don't have values for $t$ and $y$ so to estimate $q(z|x,t,y)$ we need to approximate $t$ and $y$ first. This is done by also training two separate networks that predict $t$ and $y$. The first network takes $x$ as an input and the second network takes $x$ and the predicted $t$ as an input.

\paragraph{Advantages}
\begin{itemize}
    \item The dimensionality of every function in the model can be different and is unrestricted in the size of the hidden layers
    \item  Explicitly models the distribution of the intervention variable $p(t|z)$, which allows us to sample $t$ values from our latent prior and simulate a lot of outcomes.
\end{itemize}
\paragraph{Disadvantages}
\begin{itemize}
    \item Doesn't model the log likelihood directly
    \item Have to define parameterised distributions for all observed variables
    \item Is restricted to a Gaussian distribution for the posterior.
\end{itemize}

\vspace{1cm}
\subsubsection{CEVAE + planar flow}
The second model is our first extension. it is simply the previous model with planar flows added to the end of the encoder to get a more complex posterior. This adds little disadvantage to the model, except that we have to balance more terms in our loss which can make training more difficult if it is already unstable with the CEVAE. 
\paragraph{Advantages}
\begin{itemize}
    \item The dimensionality of every function in the model can be different and is unrestricted in the size of the hidden layers
    \item  Explicitly models the distribution of the intervention variable $p(t|z)$, which allows us to sample $t$ values from our latent prior and simulate a lot of outcomes.
    \item Can have an arbitrarily complex posterior.
\end{itemize}
\paragraph{Disadvantages}
\begin{itemize}
    \item Doesn't model the log likelihood directly
    \item Have to define parameterised distributions for all observed variables
\end{itemize}



\subsubsection{Causal flow/CausalRNVP - old version}
I've left this version in the document for now
This model completely replaces the previous two models and is based on the RealNVP normalising flow. It consists of three sets of RealNVP coupling layers. The first flow maps the proxy variable $x$ to an intermediate representation. The second flow maps the outcome variable $y$ to an intermediate representation, while using $t$ as a context variable. The two intermediate representations are then concatenated and passed through the third flow to get the latent confounder $z$. The context variable is used by adding it as an additional input in the neural networks in each coupling layers that output the scaling and translation for that coupling layer. This is valid because it can be seen as just adding several bias nodes to the input of the first layer of each network, and these networks are unrestricted in their architecture. See Figure \ref{fig:two_headed_causal_flow} for a rough sketch of the model.

An intervention can be done by simply changing the context variable/intervention variable to a new value and reversing the flow, so it flows from the latent confounder $z$ to the outcome variable $y$.

\begin{figure}
    \centering
    \includestandalone{Figures/bi_headed_causal_flow_with_intervention_context}
    \caption{Causal Flow/Causal RealNVP}
    \label{fig:two_headed_causal_flow}
\end{figure}

\paragraph{Advantages}
\begin{itemize}
    \item Optimises the log likelihood directly
    \item Doesn't require parameterised distributions for the priors
    \item The two flows $f_1$ and $f_2$ can be different in both dimensionality and architecture.
\end{itemize}

\paragraph{Disadvantages}
\begin{itemize}
    \item Only models the joint distribution of $x$ and $y$. We don't model $t$ at all.
    \item Although a difference in dimensionality of $x$ and $y$ is not a problem, we do need $y$ to be at least two-dimensional if we want to use coupling layers without modifications. This is not always the case
\end{itemize} 


\subsubsection{Normalising Causal Flow}
This model came to be by combining two ideas. The previous idea of using the intervention as a 'context' variable in the flow is the first part. This gives us a way to do the intervention by passing the/a variable through the flow with a different value for the context variable. The second idea came from the paper Causal Inference with Deep Causal Graphs \cite{parafita2020causal}. The idea I took from this was to give each variable it's own prior. We then make every other variable that is a 'cause' of that variable in the causal graph part of the 'context'. In our case that would make the context of the outcome variable consist of two parts: the intervention variable and the latent confounder. As before, we infer the latent confounder through a normalising flow from our proxy variable. Put formally, we learn the following two distributions during training:
\begin{align}
    \bx &= f(\bz) \\
    \ln p(\bx) &= \ln p(\bz) - \sum \ln |\det \parfrac{f(\bz)}{\bz}| \\
    \by &= g(\by_{prior}, \bt, \bz)\\
    \ln p(\by) &= \ln p(\by_{prior}) - \sum |\det \parfrac{g(\by_{prior}, \bt, \bz)}{\by_{prior}}|
\end{align}

This seems similar as what we had before, because again we are learning two normalising flows, but now we are unconstrained by any dimensionality issues. This is because primarily we learn a mapping from $\by$ to its prior $\by_{prior}$ instead of a mapping from $\by$ to the latent confounder $\bz$.

The name of the model is somewhat arbitrary and is up for discussion.

\subsubsection{Baseline model: TARNet}
The Treatment Agnostic Representation Network is a baseline that was proposed by \cite{shalit2017estimating}. It is more of a supervised learning approach that takes the intervention variable as an additional input.

\section*{Datasets}

The three datasets that we use. IHDP is a dataset used in multiple papers, TWINS was introduced by Christos and SPACE is introduced by us. Again, this is the same as last time I emailed this.

\begin{table}[h]
    \centering
    \begin{tabular}{c|p{4cm}|p{3.5cm}|p{3.5cm}|p{4cm}}
        Datasets & Proxy variable & outcome variable & intervention variable & latent confounder \\
        \hline
        IHDP & Selection of patient measurements, both continuous and categorical & Health as single real number & Binary treatment assignment & Not known, could be general health characteristics of the patient.\\
        \hline
        TWINS & Noisy encoding of gestation variable & Health as binary variable (dead or alive) & Being taller than the other twin (binary) & gestation variable \\ 
        \hline
        SPACE & Image of the objects and the 'space ship', location can be noisy.  & Score for the new state & Movement vector of the space ship & Encoding of the location, shape, colour and gravity of the objects.\\
    \end{tabular}
    \label{tab:my_label}
\end{table}

\newpage

\section*{Metrics}
The two main values that are of interest to predict in most causal inference problems are the Individual Treatment Effect and the Average Treatment Effect:
\begin{equation}
    ITE(x) := \E[\by | \bX=x, do(\bt=1)] - \E[\by | \bX=x, do(\bt=0)], \quad ATE := \E[ITE(x)]
\end{equation}
Both are looking at the advantage or gain of doing one intervention over the other. The first one looks at individuals or groups that have the same proxy values $x$. As metrics for scoring our models we have the root mean square error of the ITE and the absolute error of the ATE: 
\begin{equation}
    RMSE_{ITE} :=\sqrt{\frac{1}{N} \sum\limits^N_{i=0} (ITE_{pred}(x_i) - ITE_{true}(x_i))^2}
\end{equation}
\begin{equation}
    AbsE_{ATE} := \left| \frac{1}{N} \sum\limits^N_{i=0} (ITE_{pred}(x_i)) - \sum\limits^N_{i=0} (ITE_{true}(x_i)) \right|
\end{equation}

The third metric that is used in earlier research is the Precision in Estimating of Heterogeneous Effet (PEHE), defined as:
\begin{equation}
    PEHE := \frac{1}{N} \sum\limits^N_{i=1} \left((y_{it_1} - y_{it_0}) - (\hat{y}_{it_1} - \hat{y}_{it_0}) \right)^2
\end{equation}
Here, $y_{t_1}$ and $y_{t_0}$ are the true outcomes under interventions $t_1$ and $t_0$, respectively. The values $\hat{y}_{t_1}$ and $\hat{y}_{t_0}$ correspond to the outcomes estimated for our model. This seems quite similar to the RMSE of the ITE, but the difference lies in the fact that the PEHE requires the actual ground-truth for both the factual and counterfactual outcome, which is only possible with (semi-)simulated datasets. The RMSE of the ITE can be calculated with just the ground truth of the event that actually took place through a law called 'ignorability'. I can't yet explain it well myself, so I just took the formula used by other research to calculate the ITE with just the one ground truth value.

% The net difference between the two is that the ITE averages after taking the difference with the ground truth ITE, so each dataset has an ITE for each sample. The ATE is one score per dataset, from which we calculate the prediction error. The error is the ATE is usually lower because errors can cancel each other out.

% For the SPACE dataset it doesn't make sense to measure this because the intervention variable is continuous, so for the time being we just have the prediction error. I did mention on Monday that the Causal RNVP model seemed to do better, and that was with regard to the root mean squared prediction error/reconstruction error on the outcome variable. However, yesterday and today I was tweaking the weighting of the components of the loss terms for the first two datasets and noticed that decreasing this reconstruction error actually increased the error on the ITE and ATE. Therefore I think I was too hasty in concluding that the Causal RNVP model seemed to perform better. It might be better to postpone that until we have a actual performance metric for continuous interventions.
% \vspace{1cm}


% Possible idea: we rephrase the ITE such that the values that $t$ takes are a bit more justified. We add two distributions for the value of $t$ in both sides of the difference from which $t$ is sampled. In the original case these are both delta distributions, resulting in the original formulation. 

% \begin{equation}
%     ITE(x) := \E[\by | \bX=x, do(\bt=t_1)] - \E[\by | \bX=x, do(\bt=t_0)], \quad t_1 \sim \delta_1, \quad t_0 \sim \delta_0
% \end{equation}
% \noindent
% This generalisation allows us to simple swap the two delta distributions with two other distributions. These new distributions can be viewed as policies, in reinforcement learning terms. What now remains is picking two distributions that we want to evaluate/compare. This would have to be dataset/problem specific. In the SPACE dataset, for example, we could pick a policy that roughly moves the spaceship towards the goal and one that either moves in a random direction or the opposite direction.

% We could also look at a synthetic 'optimal' policy that should result in the best score, given the latent confounding and compare that with a 'naive' policy that steers straight at the goal but will likely end up somewhere else:
% \begin{equation}
%     ITE(x) := \E[\by | \bX=x, do(\bt=t_1)] - \E[\by | \bX=x, do(\bt=t_0)], \quad t_1 \sim p_{optimal}(t), \quad t_0 \sim p_{control}(t)
% \end{equation}



\section*{Results}
The normalising flow model seems to do quite well, though it isn't the best on all metrics in all datasets. 


\renewcommand{\arraystretch}{1.3}
\begin{table}[h]
    \centering
    \begin{tabular}{l||c|c|c||c|c|c||c|c|c|}
        %  & & IHDP & & & TWINS & & & SPACE &\\
        & \multicolumn{3}{|c||}{IHDP} & \multicolumn{3}{|c||}{TWINS} & \multicolumn{3}{|c|}{SPACE} \\ 
         Model & ATE & ITE & PEHE & ATE & ITE & PEHE & ATE & ITE & PEHE \\
         \hline \hline
         TARNET & $\mathbf{2.24\text{e-}}1$ & $1.490$ & 2.126 &   $8.3\text{e-}2$ & $6.51\text{e-}1$ & $3.50\text{e-}1$ &     $6.96\text{e-}1$ & 2.191 & 1.241\\
         \hline
         CEVAE & $4.18\text{e-}1$ & 1.443 & 2.497 &    $1.09\text{e-}1$ & $\mathbf{3.84\textbf{e-}1}$ & $3.29\text{e-}1$ & $5.43\text{e-}1$ & 1.917 & $6.74\text{e-}1$\\
         \hline
         CEVAE + PF & $4.75\text{e-}1$ & $\mathbf{1.379}$ &  2.662 & $1.22\text{e-}1$ & $\mathbf{3.83\text{\text{e-}}1}$ & $3.27\text{e-}1$ & $6.84\text{e-}1$ & 1.913 & $5.55\text{e-}1$ \\
         \hline
         NCF & $3.32\text{e-}1$ & $2.022$ & $\mathbf{1.995}$ &    $\mathbf{3.00\text{e-}2}$ & $6.85\text{e-}1$ & $\mathbf{3.16\text{e-}1}$ & \textbf{$\mathbf{5.03\text{e-}2}$} & $\mathbf{1.846}$ & \textbf{$\mathbf{5.15\text{e-}2}$} \\
    \end{tabular}
    \caption{The scores of each model on each dataset. The cell in bold indicates the best score in each column}
    \label{tab:results_experiments}
\end{table}


\bibliographystyle{apalike}
\bibliography{references}
\end{document}


